import { Handler } from '@netlify/functions';
import { Client, validateSignature, WebhookEvent } from '@line/bot-sdk';
import { createClient } from '@supabase/supabase-js';
import OpenAI from 'openai';
import fetch from 'node-fetch';

const supabase = createClient(
  process.env.SUPABASE_URL || '',
  process.env.SUPABASE_SERVICE_ROLE_KEY || ''
);

export const handler: Handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };

  const { data: settings, error: settingsError } = await supabase.from('settings').select('*').single();
  if (settingsError || !settings) return { statusCode: 500, body: 'Failed to fetch settings' };

  const lineClient = new Client({
    channelAccessToken: settings.line_channel_access_token,
    channelSecret: settings.line_channel_secret,
  });

  const signature = event.headers['x-line-signature'] || '';
  if (!validateSignature(event.body || '', settings.line_channel_secret, signature)) {
    return { statusCode: 401, body: 'Invalid signature' };
  }

  const events: WebhookEvent[] = JSON.parse(event.body || '').events;

  for (const lineEvent of events) {
    if (lineEvent.type === 'message' && lineEvent.message.type === 'text') {
      const userId = lineEvent.source.userId!;
      const userMessage = lineEvent.message.text.trim();
      const eventId = (lineEvent as any).webhookEventId;

      // 1. å»é‡æ©Ÿåˆ¶ (é—œéµ)ï¼šåˆ©ç”¨ user_states è¡¨çš„å‚™è¨»æ¬„ä½æˆ–å°ˆç”¨æ¬„ä½ç´€éŒ„æœ€å¾Œè™•ç†çš„ Event ID
      // é¿å… AI é‹ç®—å¤ªä¹…å°è‡´ LINE é‡è¤‡ç™¼é€è«‹æ±‚
      const { data: userState } = await supabase.from('user_states').select('*').eq('line_user_id', userId).single();
      
      if (userState?.last_event_id === eventId) {
        console.log('Duplicate event detected, skipping.');
        continue; 
      }

      // æ›´æ–°æœ€å¾Œè™•ç†çš„ Event ID
      await supabase.from('user_states').upsert({ 
        line_user_id: userId, 
        last_event_id: eventId 
      });

      // 2. é—œéµå­—åµæ¸¬
      const handoverKeywords = settings.handover_keywords
        ?.replace(/ï¼Œ/g, ',')
        .split(',')
        .map((k: string) => k.trim())
        .filter((k: string) => k.length > 0) || [];
      
      // æ”¹ç”¨æ›´ç²¾ç¢ºçš„åŒ¹é…ï¼šå¦‚æœè¨Šæ¯å®Œå…¨ç­‰æ–¼é—œéµå­—ï¼Œæˆ–åŒ…å«åœ¨å…§ï¼ˆä½†æ’é™¤æ¥µçŸ­è¨Šæ¯èª¤è§¸ï¼‰
      const matchedKeyword = handoverKeywords.find((k: string) => {
        if (k.length === 1) return userMessage === k; // å–®å€‹å­—å¿…é ˆå®Œå…¨ç›¸åŒ
        return userMessage.includes(k);
      });

      if (matchedKeyword) {
        let nickname = 'åŒ¿åç”¨æˆ¶';
        try { const p = await lineClient.getProfile(userId); nickname = p.displayName; } catch (e) {}
        
        await supabase.from('user_states').upsert({ 
          line_user_id: userId, 
          nickname, 
          is_human_mode: true, 
          last_human_interaction: new Date().toISOString() 
        });

        await lineClient.replyMessage(lineEvent.replyToken, { type: 'text', text: 'å·²ç‚ºæ‚¨è½‰æ¥çœŸäººå®¢æœï¼Œè«‹ç¨å€™ã€‚' });
        
        const agentIds = settings.agent_user_ids?.split(',').map((id: string) => id.trim()).filter(Boolean);
        if (agentIds) {
          for (const id of agentIds) {
            try { await lineClient.pushMessage(id, { type: 'text', text: `ğŸ”” çœŸäººé€šçŸ¥ï¼šã€${nickname}ã€‘æ­£åœ¨å‘¼å«å°ˆäººã€‚\nè§¸ç™¼å­—ï¼š${matchedKeyword}\nåŸæ–‡ï¼š${userMessage}` }); } catch (e) {}
          }
        }
        continue;
      }

      // 3. æª¢æŸ¥ç›®å‰æ˜¯å¦åœ¨çœŸäººæ¨¡å¼
      if (userState?.is_human_mode) {
        const last = new Date(userState.last_human_interaction).getTime();
        const timeoutMs = settings.handover_timeout_minutes * 60 * 1000;
        if (new Date().getTime() - last < timeoutMs) {
          continue; // é‚„åœ¨çœŸäººæ¨¡å¼ä¸”æœªè¶…æ™‚ï¼Œä¸å›è¦†
        }
        // è¶…æ™‚äº†ï¼Œè‡ªå‹•åˆ‡å› AI
        await supabase.from('user_states').update({ is_human_mode: false }).eq('line_user_id', userId);
      }

      // 4. å‘¼å« AI (ä¸å­˜ç´€éŒ„ï¼Œä¸å‚³æ­·å²)
      if (!settings.is_ai_enabled) continue;

      let aiResult = '';
      try {
        if (settings.active_ai === 'gpt') {
          aiResult = (await callGPT(settings, userMessage)).text;
        } else {
          aiResult = await callGemini(settings, userMessage);
        }
      } catch (e: any) {
        aiResult = `âŒ AI éŒ¯èª¤ï¼š\n${e.message}`;
      }

      if (aiResult) {
        await lineClient.replyMessage(lineEvent.replyToken, { type: 'text', text: aiResult });
      }
    }
  }
  return { statusCode: 200, body: 'OK' };
};

async function callGPT(settings: any, currentMessage: string) {
  const isGPT5 = settings.gpt_model_name.includes('gpt-5');
  let fileContent = '';
  if (settings.reference_file_url) {
    try { const r = await fetch(settings.reference_file_url); if (r.ok) fileContent = await r.text(); } catch (e) {}
  }
  const systemContent = `${settings.system_prompt}\n\nåƒè€ƒæ–‡å­—ï¼š\n${settings.reference_text}\n\næª”æ¡ˆå…§å®¹ï¼š\n${fileContent}`;

  if (isGPT5) {
    const body: any = {
      model: settings.gpt_model_name,
      input: `System: ${systemContent}\nUser: ${currentMessage}`,
      reasoning: { effort: settings.gpt_reasoning_effort || 'none' },
      text: { verbosity: settings.gpt_verbosity || 'medium' }
    };
    const res = await fetch('https://api.openai.com/v1/responses', {
      method: 'POST',
      headers: { 'Authorization': `Bearer ${settings.gpt_api_key}`, 'Content-Type': 'application/json' },
      body: JSON.stringify(body)
    });
    const result: any = await res.json();
    if (!res.ok || result.error) throw new Error(result.error?.message || res.statusText);
    return { text: result.output?.text || '' };
  }

  const openai = new OpenAI({ apiKey: settings.gpt_api_key });
  const messages: any[] = [{ role: 'system', content: systemContent }, { role: 'user', content: currentMessage }];
  const params: any = { model: settings.gpt_model_name, messages };
  
  if (settings.gpt_model_name.startsWith('o1') || settings.gpt_model_name.startsWith('o3')) {
    params.max_completion_tokens = settings.gpt_max_tokens;
  } else {
    params.max_tokens = settings.gpt_max_tokens;
    params.temperature = settings.gpt_temperature;
  }
  
  const completion = await openai.chat.completions.create(params);
  return { text: completion.choices[0].message.content || '' };
}

async function callGemini(settings: any, currentMessage: string) {
  let filePart: any = null;
  if (settings.reference_file_url) {
    try {
      const r = await fetch(settings.reference_file_url);
      if (r.ok) {
        const b = await r.arrayBuffer();
        filePart = { inline_data: { data: Buffer.from(b).toString('base64'), mime_type: settings.reference_file_url.endsWith('.pdf') ? 'application/pdf' : 'text/plain' } };
      }
    } catch (e) {}
  }
  const userParts: any[] = [{ text: `System: ${settings.system_prompt}\nReference: ${settings.reference_text}` }];
  if (filePart) userParts.push(filePart);
  userParts.push({ text: `User: ${currentMessage}` });
  const contents = [{ role: 'user', parts: userParts }];

  const generationConfig: any = { temperature: 1.0, maxOutputTokens: settings.gemini_max_tokens };
  if (settings.gemini_model_name.includes('gemini-3')) {
    generationConfig.thinking_config = { include_thoughts: true, thinking_level: settings.gemini_thinking_level || 'high' };
  }

  const res = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${settings.gemini_model_name}:generateContent?key=${settings.gemini_api_key}`, {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ contents, generationConfig })
  });
  const result: any = await res.json();
  if (!res.ok || result.error) throw new Error(result.error?.message || 'Gemini API Error');
  return result.candidates?.[0]?.content?.parts?.find((p: any) => p.text)?.text || '';
}